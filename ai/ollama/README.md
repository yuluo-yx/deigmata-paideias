# Windows ç”µè„‘éƒ¨ç½² ollama3 å¹¶å®‰è£…æ¨¡å‹

> éƒ¨ç½²ä¸­ä¸ºäº†å°½å¯èƒ½å‡å°‘å¯¹æœ¬åœ°ç¯å¢ƒçš„æ±¡æŸ“ï¼Œä½¿ç”¨ Docker å®‰è£…ï¼

github: https://github.com/ollama/ollama

## å‡†å¤‡éƒ¨ç½²æ–‡ä»¶

```yml
version: '3.8'

services:
   ollama:
     volumes:
       - ./models:/root/.ollama  # å°†æœ¬åœ°æ–‡ä»¶å¤¹æŒ‚è½½åˆ°å®¹å™¨ä¸­çš„ /root/.ollama ç›®å½• ï¼ˆæ¨¡å‹ä¸‹è½½ä½ç½®ï¼‰
     container_name: ollama
     pull_policy: always
     tty: true
     restart: unless-stopped
     image: ollama/ollama:latest
     ports:
       - 11434:11434  # Ollama API ç«¯å£

   open-webui:
     build:
       context: .
       args:
         OLLAMA_BASE_URL: '/ollama'
       dockerfile: Dockerfile
     image: ghcr.io/open-webui/open-webui:main
     container_name: open-webui
     volumes:
       - ./open-webui:/app/backend/data  # å‰ç«¯é¡µé¢æ•°æ®æŒ‚è½½ä½ç½®
     depends_on:
       - ollama
     ports:
       - ${OPEN_WEBUI_PORT-3005}:8080
     environment:
       - 'OLLAMA_BASE_URL=http://ollama:11434'
       - 'WEBUI_SECRET_KEY='
     extra_hosts:
       - host.docker.internal:host-gateway
     restart: unless-stopped
```

ä¹‹åä½¿ç”¨ `docker compose up -d` ç­‰å¾…ä¸€æ®µæ—¶é—´ä¹‹åï¼Œdocker images pull æˆåŠŸã€‚å³å¯æ‰§è¡Œä¸‹ä¸€æ­¥ã€‚

## ä¸‹è½½ LLM æ¨¡å‹

LLM æ¨¡å‹å‚è€ƒï¼š

| **Model**          | **Parameters** | **Size** | **Download**                   |
| ------------------ | -------------- | -------- | ------------------------------ |
| Llama 3            | 8B             | 4.7GB    | `ollama run llama3`            |
| qwen               | 4b             | 2.3G     | `ollama run qwen:4b`           |
| Llama 3            | 70B            | 40GB     | `ollama run llama3:70b`        |
| Phi-3              | 3,8B           | 2.3GB    | `ollama run phi3`              |
| Mistral            | 7B             | 4.1GB    | `ollama run mistral`           |
| Neural Chat        | 7B             | 4.1GB    | `ollama run neural-chat`       |
| Starling           | 7B             | 4.1GB    | `ollama run starling-lm`       |
| Code Llama         | 7B             | 3.8GB    | `ollama run codellama`         |
| Llama 2 Uncensored | 7B             | 3.8GB    | `ollama run llama2-uncensored` |
| LLaVA              | 7B             | 4.5GB    | `ollama run llava`             |
| Gemma              | 2B             | 1.4GB    | `ollama run gemma:2b`          |
| Gemma              | 7B             | 4.8GB    | `ollama run gemma:7b`          |
| Solar              | 10.7B          | 6.1GB    | `ollama run solar`             |

è¿™é‡Œé€‰æ‹©æœ€å°ä½“ç§¯ä¸”æœ€å¥½ç”¨çš„æ¨¡å‹ï¼š llama3:4b æ¨¡å‹ï¼Œqwen:4b æ¨¡å‹è´¨é‡å¾ˆå·®ã€‚

```shell
ollama3 run llama3
```

æˆåŠŸä¹‹åä¼šçœ‹åˆ°ä¸‹é¢è¿™æ ·ï¼š

```shell
root@c5e5ff20a533:/# ollama run llama3
pulling manifest 
pulling 6a0746a1ec1a... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 4.7 GB                         
pulling 4fa551d4f938... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  12 KB                         
pulling 8ab4849b038c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  254 B                         
pulling 577073ffcc6c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  110 B                         
pulling 3f8eb4da87fa... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  485 B                         
verifying sha256 digest 
writing manifest 
removing any unused layers 
success 
>>> ä½ å¥½
ğŸ’– ä½ å¥½ï¼æˆ‘å¾ˆé«˜å…´åœ°çœ‹åˆ°ä½ çš„æ¶ˆæ¯ï¼ ğŸ˜Š

>>> ä½ èƒ½ä»‹ç»ä¸‹è‡ªå·±å—
ğŸ˜Š I'd be happy to introduce myself.

My name is LLaMA, and I'm a large language model trained by Meta AI. I'm a computer program designed to understand and generate human-like text, so we can have 
conversations like this one! ğŸ¤–

I was trained on a massive dataset of text from the internet, which allows me to learn about various topics, including history, science, culture, and more. This 
training enables me to answer questions, provide information, and even engage in creative writing or storytelling.

As a conversational AI, my goal is to assist and entertain users like you. I'm designed to be helpful, friendly, and respectful, so please feel free to ask me 
anything or share your thoughts with me! ğŸ’¬
```

ä¸‹è½½åçš„æ¨¡å‹å°†è¢«æŒ‚è½½åˆ°åœ¨ `./models` æ–‡ä»¶ä¸­ã€‚

## è®¿é—®

ä¸Šé¢å·²ç»ä»‹ç»äº†ä¸€ç§è®¿é—®æ–¹å¼ï¼Œé€šè¿‡ run çš„æ–¹å¼ã€‚ä¸‹é¢ä»‹ç»é€šè¿‡ web ui å’Œ api çš„æ–¹å¼è®¿é—®ã€‚

### API 

```shell
curl http://localhost:11434/api/generate -d '{
    "model":"llama3",
    "prompt": "è¯·åˆ†åˆ«ç¿»è¯‘æˆä¸­æ–‡ã€éŸ©æ–‡ã€æ—¥æ–‡ -> Meta Llama 3: The most capable openly available LLM to date",
    "stream": false
}'

curl http://localhost:11434/api/chat -d '{
  "model": "llama3",
  "messages": [
    {
      "role": "user",
      "content": "why is the sky blue?"
    }
  ],
  "stream": true
}'
```

### Web ui

æµè§ˆå™¨è®¿é—® localhost:3005å³å¯ã€‚

![image-20240718162933068](D:\AI\ollma\images\image-20240718162933068.png)



